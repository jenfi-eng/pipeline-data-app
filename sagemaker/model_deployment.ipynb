{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1bf0a9",
   "metadata": {},
   "source": [
    "# Deploy pre-trained model to Amazon SageMaker\n",
    "_**Hosting a pre-trained scikit-learn Model in Amazon SageMaker scikit-learn Container**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon SageMaker includes functionality to support a hosted notebook environment, distributed, serverless training, and real-time hosting. We think it works best when all three of these services are used together, but they can also be used independently.  Some use cases may only require hosting.  Maybe the model was trained prior to Amazon SageMaker existing, in a different service.\n",
    "\n",
    "This notebook shows how to use a pre-trained scikit-learn model with the Amazon SageMaker scikit-learn container to quickly create a hosted endpoint for that model.\n",
    "We use the California Housing dataset, present in Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html. The California Housing dataset was originally published in:\n",
    "\n",
    "> Pace, R. Kelley, and Ronald Barry. \"Sparse spatial auto-regressions.\" Statistics & Probability Letters 33.3 (1997): 291-297.\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* AWS region.\n",
    "* The IAM role arn used to give learning and hosting access to your data.\n",
    "* The S3 bucket that you want to use for training and model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee91455",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bec22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.sklearn import SKLearnModel, SKLearn\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a099d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"jenfi-sagemaker-models\"\n",
    "prefix = \"models/vn_two_mob_fifteen_plus\"\n",
    "\n",
    "print(f\"bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339c65c",
   "metadata": {},
   "source": [
    "### Prepare the model file\n",
    "\n",
    "`model_handler.py` will take a fixed name `model.pickle` when decompressed. We need to store the `.pickle` with following path:\n",
    "\n",
    "```models/model_folder_name/model.pickle```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61de8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"./models/vn_two_mob_fifteen_plus/model.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425243b",
   "metadata": {},
   "source": [
    "### Compressed the model file to a GZIP tar archive \n",
    "\n",
    "Note that the model file name must satisfy the regular expression pattern: `^[a-zA-Z0-9](-*[a-zA-Z0-9])*;`. The model file needs to be tar-zipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9153e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_tar_path = \"./models/vn_two_mob_fifteen_plus/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa131b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar czvf $model_tar_path $model_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea55281",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload the pre-trained model `model.tar.gz` file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ef0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fObj = open(model_file_path, \"rb\")\n",
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e19f0",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "This involves creating a SageMaker model from the model file previously uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848a666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(f\"model data: {model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93217e26",
   "metadata": {},
   "source": [
    "### Deploy with Python SDK\n",
    "\n",
    "Here we showcase the process of creating a model from s3 artifacts, that could be used to deploy a model that was trained in a different session or even out of SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72c571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'VnTwoMobFifteenPlus'\n",
    "\n",
    "# endpoint_name will be used to invoke model\n",
    "endpoint_name = 'VnTwoMobFifteenPlus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57815a-b5a9-4cd7-b402-71fd7687a3a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vpc_config = {\n",
    "    \"SecurityGroupIds\": [\n",
    "        \"sg-02610d5a03c041da3\",\n",
    "        \"sg-03fee2a73bcea76b6\"\n",
    "    ],\n",
    "    \"Subnets\": [\n",
    "        \"subnet-0dd112352f47d8897\",\n",
    "        \"subnet-04b844519774a51a1\",\n",
    "        \"subnet-043ccd31143339dc5\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "vpc_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c408083",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SKLearnModel(\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    entry_point=\"model_handler.py\",\n",
    "    name=model_name,\n",
    "    vpc_config=vpc_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05fe2b",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, you create the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 5-10 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f586f0e-af6a-4d1c-b08e-9a0a35916f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    capture_options=['REQUEST', 'RESPONSE'],\n",
    "    destination_s3_uri='s3://jenfi-sagemaker-data-capture',\n",
    "    sampling_percentage=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06fb61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor = model.deploy(\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    data_capture_config=data_capture_config,\n",
    "    tags=[{'Key': 'version', 'Value': '3.0'}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0c01a",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Now you can obtain the endpoint from the client library using the result from previous operations and generate classifications from the model using that endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407488f",
   "metadata": {},
   "source": [
    "### Invoke with the Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b263bbf",
   "metadata": {},
   "source": [
    "Let's generate the prediction for a single data point. We'll pick one from the test data generated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79227345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_data = {\n",
    "    'bal_month_level_min_lag_month_1_week_3_overall_level_0': 1,\n",
    "    'db_amt_month_level_median_lag_month_2_week_1_overall_level_0': 1,\n",
    "    'burn_amt_month_level_max_lag_month_2_week_2_overall_level_0': 0,\n",
    "    'outflow_inflow_ratio_cnt_day_level_lag_27_overall_level_0': 0,\n",
    "    'burn_amt_day_level_lag_43_corporate_level_0': 0\n",
    "}\n",
    "\n",
    "feat_dataframe = pd.DataFrame([row_data])\n",
    "\n",
    "feat_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ccb115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.api import add_constant\n",
    "input_predict = add_constant(feat_dataframe, has_constant='add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19a3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_predict_json = input_predict.to_json(orient='records', lines=True).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d0681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_predict_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e727f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaea88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952928ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    Body=input_predict_json,\n",
    "    ContentType=\"application/json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a596bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd233a46-3ca0-4ede-a42b-5472aa11d8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
